import { GoogleGenerativeAI } from '@google/generative-ai';
import { getSettings } from './store';
import type { StoryLanguage } from './storyStore';

const MODEL_NAME = 'gemini-2.0-flash';

export interface VocabItem {
  word: string;    // ì˜ì–´ ë‹¨ì–´
  meaning: string; // í•œê¸€ ëœ»
}

export interface GeneratedScene {
  text: string;
  imagePrompt: string;
  vocabulary?: VocabItem[]; // ì˜ì–´ ìŠ¤í† ë¦¬ë¶: ì¤‘í•™ìƒì—ê²Œ ì–´ë ¤ìš´ ë‹¨ì–´
  translation?: string;     // ì˜ì–´ ìŠ¤í† ë¦¬ë¶: í•œê¸€ ë²ˆì—­ (í•œì¤„í•´ì„ìš©)
}

export const generateStoryContent = async (topic: string, language: StoryLanguage = 'ko'): Promise<GeneratedScene[]> => {
  const { geminiApiKey, useGeminiTTS } = getSettings();

  if (!geminiApiKey) {
    throw new Error('Gemini API Keyê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì„¤ì • í˜ì´ì§€ì—ì„œ ë¨¼ì € í‚¤ë¥¼ ë“±ë¡í•´ì£¼ì„¸ìš”.');
  }

  const genAI = new GoogleGenerativeAI(geminiApiKey);

  console.log(`[Story] Using model: ${MODEL_NAME}, Language: ${language}`);

  const model = genAI.getGenerativeModel({
    model: MODEL_NAME,
  }, {
    apiVersion: 'v1beta',
    // @ts-ignore
    dangerouslyAllowBrowser: true,
  });

  let prompt: string;

  if (language === 'en') {
    // â•â•â• ì˜ì–´ ìŠ¤í† ë¦¬ë¶ â•â•â•
    const toneInstruction = useGeminiTTS
      ? "Style: Write like a warm, expressive children's storybook narrator. Use vivid imagery, playful language, and gentle emotions."
      : "Style: Write in a calm, clear, and descriptive tone suitable for children.";

    prompt = `
      Topic: "${topic}"
      
      Create a short English storybook based on the topic above.
      Even if the topic is in Korean, you MUST write the story entirely in English.
      Compose 3 to 5 scenes.
      Each scene MUST have exactly 2 sentences. No more, no less.
      
      ${toneInstruction}
      
      For each scene, also include:
      1. "vocabulary": 2~4 English words appropriate for Korean middle school students (ages 13-15) to learn, with Korean meanings.
      2. "translation": A natural Korean translation of the English text (for line-by-line study).
      
      Output ONLY raw JSON (no markdown code blocks).
      Format:
      [
        {
          "text": "Scene narration text in English",
          "imagePrompt": "Detailed English image prompt for illustrating this scene",
          "vocabulary": [
            { "word": "whimsical", "meaning": "ê¸°ë°œí•œ, ì—‰ëš±í•œ" },
            { "word": "resilient", "meaning": "íšŒë³µë ¥ ìˆëŠ”" }
          ],
          "translation": "ì´ ì¥ë©´ì˜ í•œê¸€ ë²ˆì—­"
        },
        ...
      ]
    `;
  } else {
    // â•â•â• í•œê¸€ ìŠ¤í† ë¦¬ë¶ â•â•â•
    const toneInstruction = useGeminiTTS
      ? "ìŠ¤íƒ€ì¼: ì•„ì´ë“¤ì—ê²Œ ì½ì–´ì£¼ëŠ” ë™í™”ì±…ì²˜ëŸ¼ ë§¤ìš° ê°ì •ì ì´ê³ , ë”°ëœ»í•˜ë©°, ì…ì²´ì ì¸ í‘œí˜„ì„ ì‚¬ìš©í•´. ìƒë™ê° ë„˜ì¹˜ëŠ” ì˜ì„±ì–´ì™€ ì˜íƒœì–´ë¥¼ ì ì ˆíˆ ì„ì–´ì„œ ì‘ì„±í•´ì¤˜."
      : "ìŠ¤íƒ€ì¼: ì°¨ë¶„í•˜ê³  ëª…í™•í•œ ì„¤ëª…ì¡°ë¡œ ì‘ì„±í•´ì¤˜.";

    prompt = `
      ì£¼ì œ: "${topic}"
      
      ìœ„ ì£¼ì œë¡œ ì§§ì€ ìŠ¤í† ë¦¬ë¶ì„ ë§Œë“¤ì–´ì¤˜.
      ì´ 3~5ê°œì˜ ì¥ë©´(Scene)ìœ¼ë¡œ êµ¬ì„±í•´ì¤˜.
      
      ${toneInstruction}
      
      ê²°ê³¼ëŠ” ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥í•´. (Markdown ì½”ë“œ ë¸”ë¡ ì—†ì´ ìˆœìˆ˜ JSONë§Œ)
      í˜•ì‹:
      [
        {
          "text": "ì¥ë©´ 1ì˜ ë‚˜ë ˆì´ì…˜ í…ìŠ¤íŠ¸ (í•œê¸€)",
          "imagePrompt": "ì¥ë©´ 1ì„ ê·¸ë¦¬ê¸° ìœ„í•œ ì˜ì–´ ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ (ìƒì„¸í•˜ê²Œ)"
        },
        ...
      ]
    `;
  }

  try {
    const result = await model.generateContent(prompt);
    const response = await result.response;
    const text = response.text();

    console.log('[Story] Gemini Raw Response:', text);

    const firstBracket = text.indexOf('[');
    const lastBracket = text.lastIndexOf(']');

    if (firstBracket === -1 || lastBracket === -1) {
      throw new Error('JSON í˜•ì‹ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.');
    }

    const jsonString = text.substring(firstBracket, lastBracket + 1);
    return JSON.parse(jsonString) as GeneratedScene[];
  } catch (error) {
    throw new Error(`ìŠ¤í† ë¦¬ ìƒì„± ì‹¤íŒ¨: ${(error as Error).message}`);
  }
};

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// ğŸ““ ì˜ì–´ì¼ê¸° ë³€í™˜ (Korean â†’ English Diary)
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

export interface DiaryGenerationResult {
  sentences: { english: string; korean: string }[];
  vocabulary: { word: string; meaning: string; type: 'word' | 'phrase' | 'idiom' }[];
}

export const generateEnglishDiary = async (koreanText: string): Promise<DiaryGenerationResult> => {
  const { geminiApiKey } = getSettings();
  if (!geminiApiKey) throw new Error('Gemini API Keyê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.');

  const genAI = new GoogleGenerativeAI(geminiApiKey);
  const model = genAI.getGenerativeModel({
    model: MODEL_NAME,
  }, {
    apiVersion: 'v1beta',
    // @ts-ignore
    dangerouslyAllowBrowser: true,
  });

  const prompt = `
You are an expert English teacher helping Korean students write English diaries.

The user wrote this diary entry in Korean:
"""
${koreanText}
"""

Your tasks:
1. **Convert** the Korean text into natural, fluent English diary sentences.
   - Keep the meaning faithful to the original
   - Use natural English expressions, phrasal verbs, and idioms where appropriate
   - Maximum 30 sentences. If the input is long, summarize into 30 or fewer sentences.
   - Each sentence should be a complete thought

2. **Extract vocabulary**: Find ALL meaningful English words, phrasal verbs, and idioms from the English diary.
   - Skip only the most basic words: a, an, the, I, is, am, are, was, were, be, to, of, in, on, at, it, my, and, or, but, so, do, did, not, no, this, that, for, with, as, by, up
   - Include ALL other words with Korean meanings
   - Include phrasal verbs (e.g., "wake up", "look forward to")
   - Include idioms and expressions (e.g., "on cloud nine", "a piece of cake")
   - Classify each as "word", "phrase", or "idiom"

Output ONLY raw JSON (no markdown code blocks):
{
  "sentences": [
    { "english": "I woke up early this morning.", "korean": "ë‚˜ëŠ” ì˜¤ëŠ˜ ì•„ì¹¨ ì¼ì° ì¼ì–´ë‚¬ë‹¤." },
    ...
  ],
  "vocabulary": [
    { "word": "woke up", "meaning": "ì¼ì–´ë‚˜ë‹¤, ì ì—ì„œ ê¹¨ë‹¤", "type": "phrase" },
    { "word": "early", "meaning": "ì¼ì°, ì´ë¥¸", "type": "word" },
    { "word": "morning", "meaning": "ì•„ì¹¨", "type": "word" },
    ...
  ]
}
`;

  try {
    console.log('[Diary] ğŸ““ ì˜ì–´ì¼ê¸° ìƒì„± ì¤‘...');
    const result = await model.generateContent(prompt);
    const response = await result.response;
    const text = response.text();
    console.log('[Diary] Gemini Raw Response:', text.substring(0, 300));

    const firstBrace = text.indexOf('{');
    const lastBrace = text.lastIndexOf('}');
    if (firstBrace === -1 || lastBrace === -1) {
      throw new Error('JSON í˜•ì‹ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.');
    }

    const jsonString = text.substring(firstBrace, lastBrace + 1);
    const parsed = JSON.parse(jsonString) as DiaryGenerationResult;

    // 30ë¬¸ì¥ ì œí•œ
    if (parsed.sentences.length > 30) {
      parsed.sentences = parsed.sentences.slice(0, 30);
    }

    console.log(`[Diary] âœ… ì™„ë£Œ: ${parsed.sentences.length}ë¬¸ì¥, ${parsed.vocabulary.length}ë‹¨ì–´`);
    return parsed;
  } catch (error) {
    throw new Error(`ì˜ì–´ì¼ê¸° ìƒì„± ì‹¤íŒ¨: ${(error as Error).message}`);
  }
};

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// ğŸ­ ìºë¦­í„° ì‹œíŠ¸ ìƒì„± (Character Sheet Anchoring)
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
//
// ìŠ¤í† ë¦¬ ìƒì„± í›„, ë“±ì¥ ìºë¦­í„°ì˜ ì™¸í˜•/ìŠ¤íƒ€ì¼ì„ ìƒì„¸í•˜ê²Œ ì •ì˜í•©ë‹ˆë‹¤.
// ì´ ê°€ì´ë“œë¥¼ ëª¨ë“  ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ ì•ì— ë¶™ì´ë©´
// ì¥ë©´ì´ ë°”ë€Œì–´ë„ ìºë¦­í„° ì™¸í˜•ì´ ì¼ê´€ë˜ê²Œ ìœ ì§€ë©ë‹ˆë‹¤.
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

export const generateCharacterGuide = async (
  scenes: { text: string; imagePrompt: string }[],
  _language: StoryLanguage = 'ko'
): Promise<string> => {
  const { geminiApiKey } = getSettings();
  if (!geminiApiKey) throw new Error('API Key is missing');

  const genAI = new GoogleGenerativeAI(geminiApiKey);
  const model = genAI.getGenerativeModel({
    model: MODEL_NAME,
  }, {
    apiVersion: 'v1beta',
    // @ts-ignore
    dangerouslyAllowBrowser: true,
  });

  const storyText = scenes.map((s, i) => `Scene ${i + 1}: ${s.text}`).join('\n');

  const prompt = `
You are a professional children's book illustrator creating a character design sheet.

Below is a story. Analyze ALL characters and the setting, then create a **Character & Art Style Guide** in English.

=== STORY ===
${storyText}
=== END ===

Create a concise guide following this EXACT structure. Be very specific about visual details.

**Art Style:** (e.g., "Soft watercolor children's book illustration with warm pastel tones, rounded shapes, gentle lighting")

**Characters:**
For EACH character, describe:
- Name/Role
- Species/Type (human child, animal, creature, etc.)
- Age appearance
- Hair: color, style, length
- Eyes: color, shape
- Skin/Fur: color, texture
- Outfit: specific clothing, colors, patterns
- Distinguishing features: accessories, markings, expressions
- Size/Build

**Setting Style:** (overall environment look, color palette, lighting mood)

RULES:
- Write ONLY in English
- Be extremely specific (e.g., "bright cherry-red round glasses" NOT just "glasses")
- Use specific color names (e.g., "warm honey-blonde" NOT just "blonde")
- Keep the total guide under 400 words
- Output plain text only (no markdown formatting, no code blocks)
`;

  try {
    console.log('[CharacterGuide] ğŸ­ ìºë¦­í„° ê°€ì´ë“œ ìƒì„± ì¤‘...');
    const result = await model.generateContent(prompt);
    const response = await result.response;
    const guide = response.text().trim();
    console.log('[CharacterGuide] âœ… ìºë¦­í„° ê°€ì´ë“œ ìƒì„± ì™„ë£Œ:', guide.substring(0, 200) + '...');
    return guide;
  } catch (error) {
    console.warn('[CharacterGuide] âš ï¸ ìºë¦­í„° ê°€ì´ë“œ ìƒì„± ì‹¤íŒ¨:', error);
    return '';
  }
};

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// ğŸ“ ì˜ì–´ì§€ë¬¸ì„¤ëª… (ê³ ë“±í•™ìƒ ëª¨ì˜ê³ ì‚¬ ì§€ë¬¸ ë¶„ì„)
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

export interface PassageSegment {
  segment_id: number;
  segment_role: string;
  image_prompt: string;
  script_male_original: string;
  script_female_simplified: string;
  script_male_explanation: string;
  korean_translation: string; // PDF í•œì¤„í•´ì„ìš©
}

export const generatePassageAnalysis = async (passage: string): Promise<PassageSegment[]> => {
  const { geminiApiKey } = getSettings();
  if (!geminiApiKey) throw new Error('Gemini API Keyê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.');

  const genAI = new GoogleGenerativeAI(geminiApiKey);
  const model = genAI.getGenerativeModel({
    model: MODEL_NAME,
  }, {
    apiVersion: 'v1beta',
    // @ts-ignore
    dangerouslyAllowBrowser: true,
  });

  const prompt = `
You are an expert English teacher specializing in Korean university entrance exam (ìˆ˜ëŠ¥/ëª¨ì˜ê³ ì‚¬) preparation.
Your goal is to analyze the given English passage and create a structured 5-step educational video script.

=== INPUT PASSAGE ===
${passage}
=== END PASSAGE ===

Task:
1. Divide the passage into exactly 5 logical segments (Introduction â†’ Development 1 â†’ Development 2 â†’ Key Point/Turning Point â†’ Conclusion/Summary).
2. ALL text content must be ENTIRELY in ENGLISH. Every script must be in English.
3. For each segment, create:
   - segment_role: Brief description of this segment's role
   - image_prompt: A detailed image generation prompt for an educational illustration (stylized, infographic elements, modern design)
   - script_male_original: The EXACT original passage sentences for this segment (read verbatim)
   - script_female_simplified: A VERY DETAILED and THOROUGH simplified English explanation. Break down EVERY idea in the original text step by step. Use simple vocabulary and short sentences. Explain abstract concepts with concrete examples or analogies. Paraphrase everything so a beginner can fully understand. Do NOT summarize â€” instead, EXPAND and ELABORATE on each point. Aim for at LEAST 2-3x the length of the original text. Speak as if you are a kind teacher patiently explaining to a student who is hearing this for the first time.
   - script_male_explanation: Key vocabulary (1-2 words) with English definitions AND important grammar points, all in English. Example: "'Resilient' means able to recover quickly. Notice the use of the passive voice here: 'was determined by...'"
   - korean_translation: Korean translation of the original sentences (í•œì¤„í•´ì„) for PDF export

4. Image prompts MUST include infographic elements (arrows, labels, icons, diagrams) for educational clarity.

Output ONLY raw JSON array (no markdown, no code blocks):
[
  {
    "segment_id": 1,
    "segment_role": "Introduction of the topic",
    "image_prompt": "A stylized educational illustration showing [topic]. Clean modern design with infographic elements: [specific visual elements]. Labels showing key concepts.",
    "script_male_original": "Original passage sentences...",
    "script_female_simplified": "Okay, let me break this down for you step by step. What the author is trying to say here is... Think of it like this: imagine you are... So basically, the main idea is that... And the reason this matters is because...",
    "script_male_explanation": "The key word here is 'X' which means... Also notice the grammar structure...",
    "korean_translation": "ì´ ë¶€ë¶„ì˜ í•œê¸€ í•´ì„..."
  },
  ...5 segments total
]
`;

  try {
    console.log('[ExamAnalysis] ğŸ“ ì§€ë¬¸ ë¶„ì„ ì‹œì‘...');
    const result = await model.generateContent(prompt);
    const response = await result.response;
    const text = response.text();
    console.log('[ExamAnalysis] Gemini Raw:', text.substring(0, 300));

    const firstBracket = text.indexOf('[');
    const lastBracket = text.lastIndexOf(']');
    if (firstBracket === -1 || lastBracket === -1) {
      throw new Error('JSON í˜•ì‹ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.');
    }

    const jsonString = text.substring(firstBracket, lastBracket + 1);
    const segments = JSON.parse(jsonString) as PassageSegment[];
    console.log(`[ExamAnalysis] âœ… ${segments.length}ê°œ ì„¸ê·¸ë¨¼íŠ¸ ë¶„ì„ ì™„ë£Œ`);
    return segments;
  } catch (error) {
    throw new Error(`ì§€ë¬¸ ë¶„ì„ ì‹¤íŒ¨: ${(error as Error).message}`);
  }
};

// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// Raw PCM (L16) â†’ WAV ë³€í™˜ ìœ í‹¸ë¦¬í‹°
// Gemini TTSëŠ” audio/L16;codec=pcm;rate=24000 í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•¨
// ë¸Œë¼ìš°ì €ëŠ” raw PCMì„ ì¬ìƒí•  ìˆ˜ ì—†ìœ¼ë¯€ë¡œ WAV í—¤ë”ë¥¼ ì¶”ê°€í•´ì•¼ í•¨
// â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
function pcmToWav(pcmData: Uint8Array, sampleRate: number = 24000, numChannels: number = 1, bitsPerSample: number = 16): Blob {
  const bytesPerSample = bitsPerSample / 8;
  const dataSize = pcmData.length;
  const headerSize = 44;
  const buffer = new ArrayBuffer(headerSize + dataSize);
  const view = new DataView(buffer);

  // RIFF header
  writeString(view, 0, 'RIFF');
  view.setUint32(4, 36 + dataSize, true); // file size - 8
  writeString(view, 8, 'WAVE');

  // fmt sub-chunk
  writeString(view, 12, 'fmt ');
  view.setUint32(16, 16, true); // sub-chunk size (16 for PCM)
  view.setUint16(20, 1, true); // audio format (1 = PCM)
  view.setUint16(22, numChannels, true);
  view.setUint32(24, sampleRate, true);
  view.setUint32(28, sampleRate * numChannels * bytesPerSample, true); // byte rate
  view.setUint16(32, numChannels * bytesPerSample, true); // block align
  view.setUint16(34, bitsPerSample, true);

  // data sub-chunk
  writeString(view, 36, 'data');
  view.setUint32(40, dataSize, true);

  // PCM ë°ì´í„° ë³µì‚¬
  const wavBytes = new Uint8Array(buffer);
  wavBytes.set(pcmData, headerSize);

  console.log(`[PCMâ†’WAV] Converted ${dataSize} bytes PCM â†’ ${buffer.byteLength} bytes WAV (${sampleRate}Hz, ${numChannels}ch, ${bitsPerSample}bit)`);
  return new Blob([buffer], { type: 'audio/wav' });
}

function writeString(view: DataView, offset: number, str: string) {
  for (let i = 0; i < str.length; i++) {
    view.setUint8(offset + i, str.charCodeAt(i));
  }
}

/**
 * MIME íƒ€ì…ì—ì„œ ìƒ˜í”Œë ˆì´íŠ¸ íŒŒì‹±
 * ì˜ˆ: "audio/L16;codec=pcm;rate=24000" â†’ 24000
 */
function parseSampleRate(mimeType: string): number {
  const rateMatch = mimeType.match(/rate=(\d+)/i);
  if (rateMatch) return parseInt(rateMatch[1], 10);
  return 24000; // ê¸°ë³¸ê°’
}

/**
 * Gemini Native Audio TTS
 * 
 * ì§€ì› ëª¨ë¸ (ìš°ì„ ìˆœìœ„):
 *  1. gemini-2.5-flash-preview-tts  â€” Gemini TTS Flash (ì €ì§€ì—°, ì‹¤ì‹œê°„ ëŒ€í™”ì— ìœ ë¦¬)
 *  2. gemini-2.5-pro-preview-tts    â€” Gemini TTS Pro (í’ë¶€í•œ í‘œí˜„ë ¥, ì˜¤ë””ì˜¤ë¶/íŒŸìºìŠ¤íŠ¸)
 *  3. gemini-2.0-flash-exp          â€” ë ˆê±°ì‹œ í´ë°±
 * 
 * âš¡ í•µì‹¬: raw PCM L16 â†’ WAV ë³€í™˜ í¬í•¨
 */
export const generateAudio = async (text: string, voiceName: string = 'Aoede', language: StoryLanguage = 'ko'): Promise<Blob> => {
  const { geminiApiKey } = getSettings();
  if (!geminiApiKey) throw new Error("Gemini API Key is missing");

  // ì˜¤ë””ì˜¤ ì¶œë ¥ì„ ì§€ì›í•˜ëŠ” ì „ìš© TTS ëª¨ë¸ë“¤ (ìˆœì„œëŒ€ë¡œ ì‹œë„)
  const TTS_MODELS = [
    'gemini-2.5-flash-preview-tts',   // ğŸ”¥ Gemini TTS Flash (Tier 1 ì§€ì›)
    'gemini-2.5-pro-preview-tts',     // ğŸ™ï¸ Gemini TTS Pro (ê³ í’ˆì§ˆ)
    'gemini-2.0-flash-exp',           // ë ˆê±°ì‹œ í´ë°±
  ];

  // ì–¸ì–´ë³„ í”„ë¡¬í”„íŠ¸
  const ttsPrompt = language === 'en'
    ? `Read the following text naturally and expressively: "${text}"`
    : `ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ìì—°ìŠ¤ëŸ½ê³  ê°ì •ì„ ë‹´ì•„ ì½ì–´ì£¼ì„¸ìš”: "${text}"`;

  for (const model of TTS_MODELS) {
    try {
      console.log(`[Gemini Audio] Trying model: ${model}, Voice: ${voiceName}, Lang: ${language}`);

      const url = `/api/gemini/v1beta/models/${model}:generateContent?key=${geminiApiKey}`;

      const requestBody = {
        contents: [{
          parts: [{ text: ttsPrompt }]
        }],
        generationConfig: {
          response_modalities: ["AUDIO"],
          speech_config: {
            voice_config: {
              prebuilt_voice_config: {
                voice_name: voiceName
              }
            }
          }
        }
      };

      const response = await fetch(url, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify(requestBody)
      });

      if (!response.ok) {
        const errText = await response.text();
        console.warn(`[Gemini Audio] ${model} failed (${response.status}):`, errText.substring(0, 150));
        continue; // ë‹¤ìŒ ëª¨ë¸ ì‹œë„
      }

      const data = await response.json();
      const candidate = data.candidates?.[0];
      // eslint-disable-next-line @typescript-eslint/no-explicit-any
      const audioPart = candidate?.content?.parts?.find((p: any) => p.inline_data || p.inlineData);
      const inlineData = audioPart?.inline_data || audioPart?.inlineData;

      if (inlineData && inlineData.data) {
        const base64Audio = inlineData.data;
        const binaryString = atob(base64Audio);
        const bytes = new Uint8Array(binaryString.length);
        for (let i = 0; i < binaryString.length; i++) {
          bytes[i] = binaryString.charCodeAt(i);
        }
        const mimeType = inlineData.mime_type || inlineData.mimeType || 'audio/wav';
        console.log(`[Gemini Audio] âœ… Raw data from ${model}! Size: ${bytes.length}, Type: ${mimeType}`);

        // âš¡ í•µì‹¬: L16/PCM â†’ WAV ë³€í™˜
        if (mimeType.toLowerCase().includes('l16') || mimeType.toLowerCase().includes('pcm')) {
          const sampleRate = parseSampleRate(mimeType);
          console.log(`[Gemini Audio] ğŸ”„ Raw PCM ê°ì§€ â†’ WAV ë³€í™˜ (sampleRate=${sampleRate})`);
          const wavBlob = pcmToWav(bytes, sampleRate, 1, 16);
          console.log(`[Gemini Audio] âœ… WAV ë³€í™˜ ì™„ë£Œ! Size: ${wavBlob.size}, Type: ${wavBlob.type}`);
          return wavBlob;
        }

        // ì´ë¯¸ WAV/MP3 ë“± í‘œì¤€ í¬ë§·ì´ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜
        return new Blob([bytes], { type: mimeType });
      }

      console.warn(`[Gemini Audio] ${model}: No audio data in response`);
    } catch (error) {
      console.warn(`[Gemini Audio] ${model} error:`, error);
    }
  }

  throw new Error("ëª¨ë“  Gemini TTS ëª¨ë¸ì—ì„œ ì˜¤ë””ì˜¤ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.");
};

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// ğŸ¨ ë‚˜ë…¸ ë°”ë‚˜ë‚˜ (Nano Banana) ì´ë¯¸ì§€ ìƒì„±
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
//
// ì „ëµ ìˆœì„œ (Tier 1 API Key ê¸°ì¤€):
//  1) gemini-2.5-flash-image       â€” ë‚˜ë…¸ ë°”ë‚˜ë‚˜ (ë¹ ë¥¸ ì†ë„, íš¨ìœ¨ì )
//  2) gemini-3-pro-image-preview   â€” ë‚˜ë…¸ ë°”ë‚˜ë‚˜ í”„ë¡œ (4K, ì •êµí•œ í…ìŠ¤íŠ¸)
//  3) gemini-2.0-flash-exp         â€” ë ˆê±°ì‹œ ì´ë¯¸ì§€ ìƒì„±
//  4) Pollinations.ai              â€” ë¬´ë£Œ í´ë°± (API í‚¤ ë¶ˆí•„ìš”)
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

export const generateSceneImage = async (imagePrompt: string, characterGuide?: string): Promise<string> => {
  const { geminiApiKey } = getSettings();
  if (!geminiApiKey) throw new Error("Gemini API Key is missing");

  // ìºë¦­í„° ê°€ì´ë“œê°€ ìˆìœ¼ë©´ ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ ì•ì— ë¶™ì—¬ì„œ ì¼ê´€ì„± ìœ ì§€
  const characterAnchor = characterGuide
    ? `[CHARACTER & STYLE REFERENCE - Follow these descriptions EXACTLY for visual consistency across all scenes]\n${characterGuide}\n\n[SCENE TO ILLUSTRATE]\n`
    : 'Style: warm, colorful, whimsical, digital painting. ';

  const prompt = `Generate a beautiful children's storybook illustration. No text or words in the image.\n\n${characterAnchor}Scene: ${imagePrompt}`;

  // â”€â”€ ğŸ”¥ Strategy 1: ë‚˜ë…¸ ë°”ë‚˜ë‚˜ ëª¨ë¸ë“¤ (REST API) â”€â”€
  // gemini-2.5-flash-image (ë¹ ë¦„) â†’ gemini-3-pro-image-preview (ê³ í’ˆì§ˆ)
  const nanoBananaModels = [
    { model: 'gemini-2.5-flash-image', apiVer: 'v1beta', label: 'ğŸŒ ë‚˜ë…¸ ë°”ë‚˜ë‚˜ (Flash)' },
    { model: 'gemini-2.5-flash-image', apiVer: 'v1alpha', label: 'ğŸŒ ë‚˜ë…¸ ë°”ë‚˜ë‚˜ (Flash, v1alpha)' },
    { model: 'gemini-3-pro-image-preview', apiVer: 'v1beta', label: 'ğŸŒ ë‚˜ë…¸ ë°”ë‚˜ë‚˜ Pro' },
    { model: 'gemini-3-pro-image-preview', apiVer: 'v1alpha', label: 'ğŸŒ ë‚˜ë…¸ ë°”ë‚˜ë‚˜ Pro (v1alpha)' },
  ];

  for (const { model, apiVer, label } of nanoBananaModels) {
    try {
      console.log(`[Image] ğŸ¨ ${label} ì‹œë„: ${model} (${apiVer})`);

      const url = `/api/gemini/${apiVer}/models/${model}:generateContent?key=${geminiApiKey}`;

      const requestBody = {
        contents: [{ parts: [{ text: prompt }] }],
        generationConfig: {
          response_modalities: ["IMAGE", "TEXT"],
        }
      };

      const response = await fetch(url, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify(requestBody)
      });

      if (!response.ok) {
        const errText = await response.text();
        console.warn(`[Image] ${label} ì‹¤íŒ¨ (${response.status}):`, errText.substring(0, 200));
        continue;
      }

      const data = await response.json();
      const result = extractImageFromResponse(data);
      if (result) {
        console.log(`[Image] âœ… ${label} ì„±ê³µ!`);
        return result;
      }
      console.warn(`[Image] ${label}: ì‘ë‹µì— ì´ë¯¸ì§€ ì—†ìŒ`);
    } catch (error) {
      console.warn(`[Image] ${label} ì—ëŸ¬:`, error);
    }
  }

  // â”€â”€ Strategy 2: SDK ê¸°ë°˜ ë‚˜ë…¸ ë°”ë‚˜ë‚˜ ì‹œë„ â”€â”€
  const sdkModels = ['gemini-2.5-flash-image', 'gemini-3-pro-image-preview', 'gemini-2.0-flash-exp'];
  for (const sdkModel of sdkModels) {
    try {
      console.log(`[Image] ğŸ¨ SDK ì‹œë„: ${sdkModel}`);
      const genAI = new GoogleGenerativeAI(geminiApiKey);
      const model = genAI.getGenerativeModel({
        model: sdkModel,
        // @ts-ignore â€” responseModalitiesëŠ” SDK íƒ€ì…ì— ì•„ì§ ì—†ì„ ìˆ˜ ìˆìŒ
        generationConfig: { responseModalities: ['Image', 'Text'] },
      }, {
        apiVersion: 'v1beta',
        // @ts-ignore
        dangerouslyAllowBrowser: true,
      });

      const result = await model.generateContent(prompt);
      const response = result.response;
      const parts = response.candidates?.[0]?.content?.parts || [];

      for (const part of parts) {
        // @ts-ignore â€” inlineData íƒ€ì…ì´ SDKì—ì„œ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ
        const inlineData = part.inlineData || part.inline_data;
        if (inlineData?.data && (inlineData?.mimeType?.startsWith('image') || inlineData?.mime_type?.startsWith('image'))) {
          const mimeType = inlineData.mimeType || inlineData.mime_type || 'image/png';
          console.log(`[Image] âœ… SDK ì„±ê³µ (${sdkModel})!`);
          return `data:${mimeType};base64,${inlineData.data}`;
        }
      }
      console.warn(`[Image] SDK (${sdkModel}): ì‘ë‹µì— ì´ë¯¸ì§€ ì—†ìŒ`);
    } catch (error) {
      console.warn(`[Image] SDK (${sdkModel}) ì—ëŸ¬:`, error);
    }
  }

  // â”€â”€ Strategy 3: ë ˆê±°ì‹œ REST API í´ë°± â”€â”€
  const legacyAttempts = [
    { model: 'gemini-2.0-flash-exp', apiVer: 'v1beta' },
    { model: 'gemini-2.0-flash-exp', apiVer: 'v1alpha' },
    { model: 'gemini-2.0-flash-preview-image-generation', apiVer: 'v1beta' },
  ];

  for (const { model, apiVer } of legacyAttempts) {
    try {
      console.log(`[Image] ğŸ¨ ë ˆê±°ì‹œ REST ì‹œë„: ${model} (${apiVer})`);

      const url = `/api/gemini/${apiVer}/models/${model}:generateContent?key=${geminiApiKey}`;

      const requestBody = {
        contents: [{ parts: [{ text: prompt }] }],
        generationConfig: {
          response_modalities: ["IMAGE", "TEXT"],
        }
      };

      const response = await fetch(url, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify(requestBody)
      });

      if (!response.ok) {
        const errText = await response.text();
        console.warn(`[Image] ${model}(${apiVer}) ì‹¤íŒ¨ (${response.status}):`, errText.substring(0, 150));
        continue;
      }

      const data = await response.json();
      const result = extractImageFromResponse(data);
      if (result) {
        console.log(`[Image] âœ… ${model}(${apiVer}) ì„±ê³µ!`);
        return result;
      }
      console.warn(`[Image] ${model}(${apiVer}): ì‘ë‹µì— ì´ë¯¸ì§€ ì—†ìŒ`);
    } catch (error) {
      console.warn(`[Image] ${model} ì—ëŸ¬:`, error);
    }
  }

  // â”€â”€ Strategy 4: Imagen API â”€â”€
  const imagenModels = ['imagen-3.0-generate-001', 'imagen-3.0-generate-002', 'imagen-3.0-fast-generate-001'];
  for (const imagenModel of imagenModels) {
    try {
      console.log(`[Image] ğŸ¨ Imagen ì‹œë„: ${imagenModel}`);

      const url = `/api/gemini/v1beta/models/${imagenModel}:predict?key=${geminiApiKey}`;
      const requestBody = {
        instances: [{ prompt: `children's storybook illustration: ${imagePrompt}` }],
        parameters: { sampleCount: 1, aspectRatio: "16:9" }
      };

      const response = await fetch(url, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify(requestBody)
      });

      if (!response.ok) continue;

      const data = await response.json();
      const predictions = data.predictions || [];
      if (predictions[0]?.bytesBase64Encoded) {
        console.log(`[Image] âœ… ${imagenModel} ì„±ê³µ!`);
        return `data:image/png;base64,${predictions[0].bytesBase64Encoded}`;
      }
    } catch {
      // ë‹¤ìŒ ì‹œë„
    }
  }

  // â”€â”€ Strategy 5: Pollinations.ai (ë¬´ë£Œ, API í‚¤ ë¶ˆí•„ìš”, CORS í—ˆìš©) â”€â”€
  try {
    console.log(`[Image] ğŸ¨ Pollinations.ai í´ë°± ì‹œë„...`);
    const pollinationsPrompt = encodeURIComponent(
      `children's storybook illustration, warm colors, whimsical, digital painting, no text: ${imagePrompt}`
    );
    const pollinationsUrl = `https://image.pollinations.ai/prompt/${pollinationsPrompt}?width=1280&height=720&nologo=true&seed=${Date.now()}`;

    const response = await fetch(pollinationsUrl);
    if (response.ok) {
      const blob = await response.blob();
      if (blob.size > 1000 && blob.type.startsWith('image')) {
        console.log(`[Image] âœ… Pollinations.ai ì„±ê³µ! Size: ${blob.size} bytes`);
        // Blob â†’ data URL
        return new Promise<string>((resolve, reject) => {
          const reader = new FileReader();
          reader.onloadend = () => resolve(reader.result as string);
          reader.onerror = reject;
          reader.readAsDataURL(blob);
        });
      }
    }
    console.warn(`[Image] Pollinations.ai ì‹¤íŒ¨:`, response.status);
  } catch (error) {
    console.warn(`[Image] Pollinations.ai ì—ëŸ¬:`, error);
  }

  throw new Error("ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨: ëª¨ë“  ë°©ë²•ì„ ì‹œë„í–ˆìŠµë‹ˆë‹¤. Gemini API í‚¤ê°€ ì´ë¯¸ì§€ ìƒì„±ì„ ì§€ì›í•˜ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.");
};

// eslint-disable-next-line @typescript-eslint/no-explicit-any
function extractImageFromResponse(data: any): string | null {
  const parts = data?.candidates?.[0]?.content?.parts || [];
  for (const part of parts) {
    const inlineData = part.inline_data || part.inlineData;
    if (inlineData?.data) {
      const mimeType = inlineData.mime_type || inlineData.mimeType || 'image/png';
      if (mimeType.startsWith('image')) {
        return `data:${mimeType};base64,${inlineData.data}`;
      }
    }
  }
  return null;
}
